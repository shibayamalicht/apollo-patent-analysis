import streamlit as st
import platform
import os
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import string
import re
import json
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import euclidean_distances

# ==================================================================
# --- 1. ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š (å…±é€š) ---
# ==================================================================
def get_japanese_font_path():
    """OSã‚’åˆ¤å®šã—ã¦é©åˆ‡ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãƒ‘ã‚¹ã‚’è¿”ã™"""
    system = platform.system()
    font_paths = []
    
    if system == "Darwin": # Mac
        font_paths = [
            "/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W3.ttc",
            "/System/Library/Fonts/Hiragino Sans W3.ttc",
            "/System/Library/Fonts/Hiragino Kaku Gothic ProN.ttc",
            "/Library/Fonts/AppleGothic.ttf",
            "/System/Library/Fonts/AppleSDGothicNeo.ttc" 
        ]
    elif system == "Windows": # Windows
        font_paths = [
            "C:/Windows/Fonts/meiryo.ttc",
            "C:/Windows/Fonts/msgothic.ttc",
            "C:/Windows/Fonts/yugothr.ttc",
            "C:/Windows/Fonts/YuGothR.ttc"
        ]
    else: # Linux (Streamlit Cloudãªã©)
        font_paths = [
            "/usr/share/fonts/opentype/ipafont-gothic/ipagp.ttf",
            "/usr/share/fonts/truetype/fonts-japanese-gothic.ttf",
            "/usr/share/fonts/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/noto/NotoSansCJKjp-Regular.otf"
        ]
        
    for path in font_paths:
        if os.path.exists(path): return path
    return None

def configure_matplotlib_font():
    """Matplotlibã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’é©ç”¨ã™ã‚‹"""
    font_path = get_japanese_font_path()
    if font_path:
        try:
            prop = fm.FontProperties(fname=font_path)
            plt.rcParams['font.family'] = prop.get_name()
            return font_path
        except:
            pass
    return None

# ==================================================================
# --- 2. ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ (å…±é€š) ---
# ==================================================================
# åŸºæœ¬ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ

# 1. ä¸€èˆ¬çš„ãªæ—¥æœ¬èªã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ¥ç¶šè©ãƒ»ä»£åè©ãƒ»å½¢å¼åè©ãªã©ï¼‰
_sw_general = [
    "ã™ã‚‹","ã‚ã‚‹","ãªã‚‹","ãŸã‚","ã“ã¨","ã‚ˆã†","ã‚‚ã®","ã“ã‚Œ","ãã‚Œ","ã‚ã‚Œ","ã“ã“","ãã“","ã©ã‚Œ","ã©ã®",
    "ã“ã®","ãã®","å½“è©²","è©²","ãŠã‚ˆã³","åŠã³","ã¾ãŸã¯","ã¾ãŸ","ä¾‹ãˆã°","ä¾‹ãˆã°ã¯","ã«ãŠã„ã¦","ã«ã‚ˆã‚Š",
    "ã«å¯¾ã—ã¦","ã«é–¢ã—ã¦","ã«ã¤ã„ã¦","ã¨ã—ã¦","ã¨ã—ã¦ã¯","å ´åˆ","ä¸€æ–¹","ä»–æ–¹","ã•ã‚‰ã«","ãã—ã¦","ãŸã ã—",
    "ãªãŠ","ç­‰","ãªã©","ç­‰ã€…","ã„ã‚ã‚†ã‚‹","æ‰€è¬‚","åŒæ§˜","åŒæ™‚","å‰è¨˜","æœ¬","åŒ","å„","å„ç¨®","æ‰€å®š","æ‰€æœ›",
    "ä¸€ä¾‹","ä»–","ä¸€éƒ¨","ä¸€ã¤","è¤‡æ•°","å°‘ãªãã¨ã‚‚","å°‘ãªãã¨ã‚‚ä¸€ã¤","ä¸Šè¨˜","ä¸‹è¨˜","å‰è¿°","å¾Œè¿°","æ—¢è¿°",
    "é–¢ã™ã‚‹","åŸºã¥ã","ç”¨ã„ã‚‹","ä½¿ç”¨","åˆ©ç”¨","æœ‰ã™ã‚‹","å«ã‚€","å‚™ãˆã‚‹","è¨­ã‘ã‚‹","ã™ãªã‚ã¡","å¾“ã£ã¦",
    "ã—ã‹ã—ãªãŒã‚‰","æ¬¡ã«","ç‰¹ã«","å…·ä½“çš„ã«","è©³ç´°ã«","ã„ãšã‚Œ","ã†ã¡","ãã‚Œãã‚Œ","ã¨ã",
    "ã‹ã‹ã‚‹","ã‹ã‚ˆã†ãª","ã‹ã‹ã‚‹å ´åˆ","æœ¬ä»¶","æœ¬é¡˜","æœ¬å‡ºé¡˜","æœ¬æ˜ç´°æ›¸","ã“ã‚Œã‚‰","ãã‚Œã‚‰","å„ã€…","éšæ™‚","é©å®œ",
    "ä»»æ„","å¿…ãšã—ã‚‚","é€šå¸¸","ä¸€èˆ¬ã«","å…¸å‹çš„","ä»£è¡¨çš„","ä¸¦ã³ã«","è‹¥ã—ãã¯","åˆã¯","ä¸”ã¤","å³ã¡","ä½•ã‚‰","ä¸€åˆ‡",
    "ä¿‚ã‚‹","é–¢ã‚ã‚‹","ä»‹ã—ã¦","æ²¿ã£ã¦","ä¼´ã†","åŸºã¥ã„ã¦","æ›´ãªã‚‹","å˜æ•°","å…¨ä½“","å…¨éƒ¨","å¤§åŠ","ç´„","æ¦‚ã—ã¦","ã»ã¼",
    "ã§ãã‚‹", "ã„ã‚‹", "æ˜ç´°æ›¸", "è§£æ±º", "æº–å‚™", "æä¾›", "ç™ºç”Ÿ", "æœªæº€", "è¶…", "éš›", "ååˆ†"
]

# 2. ç‰¹è¨±ç‰¹æœ‰ã®å°‚é–€ç”¨èªãƒ»å®šå‹å¥ãƒ»åŒºåˆ†
_sw_patent_terms = [
    "æœ¬ç™ºæ˜","ç™ºæ˜","å®Ÿæ–½ä¾‹","å®Ÿæ–½å½¢æ…‹","å¤‰å½¢ä¾‹","è«‹æ±‚","è«‹æ±‚é …","å›³","å›³é¢","ç¬¦å·","ç¬¦å·ã®èª¬æ˜",
    "å›³é¢ã®ç°¡å˜ãªèª¬æ˜","ç™ºæ˜ã®è©³ç´°ãªèª¬æ˜","æŠ€è¡“åˆ†é‡","èƒŒæ™¯æŠ€è¡“","å¾“æ¥æŠ€è¡“","ç™ºæ˜ãŒè§£æ±ºã—ã‚ˆã†ã¨ã™ã‚‹èª²é¡Œ","èª²é¡Œ",
    "è§£æ±ºæ‰‹æ®µ","åŠ¹æœ","è¦ç´„","ç™ºæ˜ã®åŠ¹æœ","ç›®çš„","æ‰‹æ®µ","æ§‹æˆ","æ§‹é€ ","å·¥ç¨‹","å‡¦ç†","æ–¹æ³•","æ‰‹æ³•","æ–¹å¼",
    "ç‰¹å¾´","ç‰¹å¾´ã¨ã™ã‚‹","ç‰¹å¾´éƒ¨","ã‚¹ãƒ†ãƒƒãƒ—","ãƒ•ãƒ­ãƒ¼","ã‚·ãƒ¼ã‚±ãƒ³ã‚¹","å®šç¾©",
    "é–¢ä¿‚","å¯¾å¿œ","æ•´åˆ","å®Ÿæ–½ã®å½¢æ…‹","å®Ÿæ–½ã®æ…‹æ§˜","æ…‹æ§˜","å¤‰å½¢","ä¿®æ­£ä¾‹","å›³ç¤º","å›³ç¤ºä¾‹","å›³ç¤ºã—ãªã„",
    "å‚ç…§","å‚ç…§ç¬¦å·","æ®µè½","è©³ç´°èª¬æ˜","è¦æ—¨","ä¸€å®Ÿæ–½å½¢æ…‹","ä»–ã®å®Ÿæ–½å½¢æ…‹","ä¸€å®Ÿæ–½ä¾‹","åˆ¥ã®å´é¢","ä»˜è¨˜",
    "é©ç”¨ä¾‹","ç”¨èªã®å®šç¾©","é–‹ç¤º","æœ¬é–‹ç¤º","é–‹ç¤ºå†…å®¹","è¨˜è¼‰","è¨˜è¿°","æ²è¼‰","è¨€åŠ","å†…å®¹","è©³ç´°","èª¬æ˜","è¡¨è¨˜","è¡¨ç¾","ç®‡æ¡æ›¸ã","ä»¥ä¸‹ã®","ä»¥ä¸Šã®","å…¨ã¦ã®","ä»»æ„ã®","ç‰¹å®šã®",
    "å‡ºé¡˜","å‡ºé¡˜äºº","å‡ºé¡˜ç•ªå·","å‡ºé¡˜æ—¥","å‡ºé¡˜æ›¸","å‡ºé¡˜å…¬é–‹","å…¬é–‹","å…¬é–‹ç•ªå·",
    "å…¬é–‹å…¬å ±","å…¬å ±","å…¬å ±ç•ªå·","ç‰¹è¨±","ç‰¹è¨±ç•ªå·","ç‰¹è¨±æ–‡çŒ®","éç‰¹è¨±æ–‡çŒ®","å¼•ç”¨","å¼•ç”¨æ–‡çŒ®","å…ˆè¡ŒæŠ€è¡“",
    "å¯©æŸ»","å¯©æŸ»å®˜","æ‹’çµ¶","æ„è¦‹æ›¸","è£œæ­£æ›¸","å„ªå…ˆ","å„ªå…ˆæ—¥","åˆ†å‰²å‡ºé¡˜","ç¶™ç¶šå‡ºé¡˜","å›½å†…ç§»è¡Œ","å›½éš›å‡ºé¡˜",
    "å›½éš›å…¬é–‹","PCT","ç™»éŒ²","å…¬é–‹æ—¥","å¯©æŸ»è«‹æ±‚","æ‹’çµ¶ç†ç”±","è£œæ­£","è¨‚æ­£","ç„¡åŠ¹å¯©åˆ¤","ç•°è­°","å–æ¶ˆ","å–ä¸‹ã’",
    "å…¬çŸ¥","å‘¨çŸ¥","æ…£ç”¨","æ—¢çŸ¥","å¸‚è²©","å®¹æ˜“","å›°é›£","ä¸å¯èƒ½","é‡è¦","å•é¡Œ","çµæœ","ä½œç”¨",
    "äº‹ä»¶ç•ªå·","ä»£ç†äºº","å¼ç†å£«","ä¿‚å±","çµŒé", "æ¯”è¼ƒä¾‹","å‚è€ƒä¾‹","è©¦é¨“","è©¦æ–™","è©•ä¾¡","æ¡ä»¶","å®Ÿé¨“","å®Ÿé¨“ä¾‹"
]

# 3. æ§‹é€ ãƒ»ä½ç½®ãƒ»æ–¹å‘ãƒ»å½¢çŠ¶ï¼ˆä¸€èˆ¬åè©ï¼‰
_sw_structure = [
    "ä¸Šéƒ¨","ä¸‹éƒ¨","å†…éƒ¨","å¤–éƒ¨","å†…å´","å¤–å´","è¡¨é¢","è£é¢","å´é¢","ä¸Šé¢","ä¸‹é¢","ç«¯é¢","å…ˆç«¯","åŸºç«¯","å¾Œç«¯","ä¸€ç«¯","ä»–ç«¯","ä¸­å¿ƒ","ä¸­å¤®","å‘¨ç¸","å‘¨è¾º",
    "è¿‘å‚","æ–¹å‘","ä½ç½®","ç©ºé–“","é ˜åŸŸ","ç¯„å›²","é–“éš”","è·é›¢","å½¢çŠ¶","å½¢æ…‹","çŠ¶æ…‹","ç¨®é¡","å±¤","è†œ","éƒ¨",
    "éƒ¨æ","éƒ¨ä½","éƒ¨å“","æ©Ÿæ§‹","è£…ç½®","å®¹å™¨","çµ„æˆ","ææ–™","ç”¨é€”","é©ç”¨","é©ç”¨ä¾‹","ç‰‡å´","ä¸¡å´","å·¦å´",
    "å³å´","å‰æ–¹","å¾Œæ–¹","ä¸Šæµ","ä¸‹æµ","éš£æ¥","è¿‘æ¥","é›¢é–“","é–“ç½®","ä»‹åœ¨","é‡ç•³","æ¦‚ã­","ç•¥","ç•¥ä¸­å¤®",
    "å›ºå®šå´","å¯å‹•å´","ä¼¸é•·","åç¸®","ä¿‚åˆ","åµŒåˆ","å–ä»˜","é€£çµéƒ¨","æ”¯æŒä½“","æ”¯æŒéƒ¨","ã‚¬ã‚¤ãƒ‰éƒ¨",
    "è»¸","ã‚·ãƒ£ãƒ•ãƒˆ","ã‚®ã‚¢","ãƒ¢ãƒ¼ã‚¿","ã‚¨ãƒ³ã‚¸ãƒ³","ã‚¢ã‚¯ãƒãƒ¥ã‚¨ãƒ¼ã‚¿","ã‚»ãƒ³ã‚µ","ãƒãƒ«ãƒ–","ãƒãƒ³ãƒ—","ç­ä½“","ãƒã‚¦ã‚¸ãƒ³ã‚°","ãƒ•ãƒ¬ãƒ¼ãƒ ",
    "ã‚·ãƒ£ãƒ¼ã‚·","é§†å‹•","ä¼é”","æ”¯æŒ","é€£çµ", "å‡¦ç†è£…ç½®","ç«¯æœ«","ãƒ¦ãƒ‹ãƒƒãƒˆ","ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«","å›è·¯","ç´ å­"
]

# 4. ITãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»åˆ¶å¾¡é–¢é€£
_sw_it_control = [
    "ã‚·ã‚¹ãƒ†ãƒ ","ãƒ—ãƒ­ã‚°ãƒ©ãƒ ","è¨˜æ†¶åª’ä½“","ãƒ‡ãƒ¼ã‚¿","æƒ…å ±","ä¿¡å·","å‡ºåŠ›","å…¥åŠ›","åˆ¶å¾¡","æ¼”ç®—","å–å¾—","é€ä¿¡","å—ä¿¡","è¡¨ç¤º","é€šçŸ¥","è¨­å®š","å¤‰æ›´",
    "æ›´æ–°","ä¿å­˜","å‰Šé™¤","è¿½åŠ ","å®Ÿè¡Œ","é–‹å§‹","çµ‚äº†","ç¶™ç¶š","åœæ­¢","åˆ¤å®š","åˆ¤æ–­","æ±ºå®š","é¸æŠ","ç‰¹å®š",
    "æŠ½å‡º","æ¤œå‡º","æ¤œçŸ¥","æ¸¬å®š","è¨ˆæ¸¬","ç§»å‹•","å›è»¢","å¤‰ä½","å¤‰å½¢","å›ºå®š","é…ç½®","ç”Ÿæˆ","ä»˜ä¸","ä¾›çµ¦",
    "é©ç”¨","ç…§åˆ","æ¯”è¼ƒ","ç®—å‡º","è§£æ","åŒå®š","åˆæœŸåŒ–","èª­å‡º","æ›¸è¾¼","ç™»éŒ²","è¨˜éŒ²","é…ä¿¡","é€£æº","åˆ‡æ›¿",
    "èµ·å‹•","å¾©å¸°","ç›£è¦–","é€šçŸ¥å‡¦ç†","å–å¾—å‡¦ç†","æ¼”ç®—å‡¦ç†",
    "é›»æº","é›»åœ§","é›»æµ","ä¿¡å·ç·š","é…ç·š","ç«¯å­","ç«¯éƒ¨","æ¥ç¶š","æ¥ç¶šéƒ¨","æ¼”ç®—éƒ¨","è¨˜æ†¶éƒ¨","è¨˜æ†¶è£…ç½®","è¨˜éŒ²åª’ä½“",
    "ãƒ¦ãƒ¼ã‚¶","åˆ©ç”¨è€…","ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ","ã‚µãƒ¼ãƒ","ç”»é¢","UI","GUI",
    "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹","ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹","DB","ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯","é€šä¿¡","è¦æ±‚","å¿œç­”","ãƒªã‚¯ã‚¨ã‚¹ãƒˆ","ãƒ¬ã‚¹ãƒãƒ³ã‚¹","ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
    "å¼•æ•°","å±æ€§","ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£","ãƒ•ãƒ©ã‚°","ID","ãƒ•ã‚¡ã‚¤ãƒ«","ãƒ‡ãƒ¼ã‚¿æ§‹é€ ","ãƒ†ãƒ¼ãƒ–ãƒ«","ãƒ¬ã‚³ãƒ¼ãƒ‰"
]

# 5. åŒ–å­¦ãƒ»ææ–™ãƒ»å®Ÿé¨“æ¡ä»¶
_sw_chemistry = [
    "æº¶æ¶²","æº¶åª’","è§¦åª’","åå¿œ","ç”Ÿæˆç‰©","åŸæ–™","æˆåˆ†","å«æœ‰","å«æœ‰é‡","é…åˆ","æ··åˆ","æ··åˆç‰©","æ¿ƒåº¦","æ¸©åº¦","æ™‚é–“",
    "å‰²åˆ","æ¯”ç‡","åŸº","å®˜èƒ½åŸº","åŒ–åˆç‰©","çµ„æˆç‰©","æ¨¹è„‚","ãƒãƒªãƒãƒ¼","ãƒ¢ãƒãƒãƒ¼","åŸºæ¿","åŸºæ","ãƒ•ã‚£ãƒ«ãƒ ","ã‚·ãƒ¼ãƒˆ",
    "ç²’å­","ç²‰æœ«","åå¿œæ¡ä»¶","åå¿œæ™‚é–“","åå¿œæ¸©åº¦",
    "è‰¯å¥½","å®¹æ˜“","ç°¡ä¾¿","é©åˆ‡","æœ‰åˆ©","æœ‰ç”¨","æœ‰åŠ¹",
    "åŠ¹æœçš„","é«˜ã„","ä½ã„","å¤§ãã„","å°ã•ã„","æ–°è¦","æ”¹è‰¯","æ”¹å–„","æŠ‘åˆ¶","å‘ä¸Š","ä½æ¸›","å‰Šæ¸›","å¢—åŠ ",
    "æ¸›å°‘","å¯èƒ½","å¥½é©","å¥½ã¾ã—ã„","æœ›ã¾ã—ã„","å„ªã‚Œã‚‹","å„ªã‚ŒãŸ","é«˜æ€§èƒ½","é«˜åŠ¹ç‡","ä½ã‚³ã‚¹ãƒˆ","ã‚³ã‚¹ãƒˆ",
    "ç°¡æ˜“","å®‰å®š","å®‰å®šæ€§","è€ä¹…","è€ä¹…æ€§","ä¿¡é ¼æ€§","ç°¡ç´ ","ç°¡ç•¥","å˜ç´”","æœ€é©","æœ€é©åŒ–","æ±ç”¨","æ±ç”¨æ€§",
    "å®Ÿç¾","é”æˆ","ç¢ºä¿","ç¶­æŒ","é˜²æ­¢","å›é¿","ä¿ƒé€²","ä¸è¦","å¿…è¦","é«˜ç²¾åº¦","çœé›»åŠ›","çœè³‡æº","é«˜ä¿¡é ¼",
    "ä½è² è·","é«˜ç´”åº¦","é«˜å¯†åº¦","é«˜æ„Ÿåº¦","è¿…é€Ÿ","å††æ»‘","ç°¡ç•¥åŒ–","ä½ä¾¡æ ¼","å®ŸåŠ¹çš„","å¯èƒ½åŒ–","æœ‰åŠ¹åŒ–",
    "éå¿…é ˆ","é©åˆ","äº’æ›"
]

# 6. æ•°å­—ãƒ»å˜ä½ãƒ»ç‰¹æ®Šè¨˜å·ãƒ»æ³•äººæ ¼
_sw_misc = [
    "ç¬¬","ç¬¬ä¸€","ç¬¬äºŒ","ç¬¬ä¸‰","ç¬¬1","ç¬¬ï¼’","ç¬¬ï¼“","ç¬¬ï¼‘","ç¬¬ï¼’","ç¬¬ï¼“","ï¼‘","ï¼’","ï¼“","ï¼”","ï¼•","ï¼–","ï¼—","ï¼˜","ï¼™","ï¼",
    "ä¸€","äºŒ","ä¸‰","å››","äº”","å…­","ä¸ƒ","å…«","ä¹","é›¶","æ•°","è¤‡åˆ","å¤šæ•°","å°‘æ•°","å›³1","å›³2","å›³3","å›³4","å›³5","å›³6","å›³7","å›³8","å›³9",
    "è¡¨1","è¡¨2","è¡¨3","å¼1","å¼2","å¼3","ï¼","ï¼‘","ï¼’","ï¼“","ï¼”","ï¼•","ï¼–","ï¼—","ï¼˜","ï¼™","%","ï¼…","wt%","vol%","è³ªé‡%","é‡é‡%","å®¹é‡%","mol","mol%","mol/L","M","mm","cm","m","nm","Î¼m","Î¼","rpm",
    "Pa","kPa","MPa","GPa","N","W","V","A","mA","Hz","kHz","MHz","GHz","â„ƒ","Â°C","K","mL","L","g","kg","mg","wt","vol",
    "h","hr","hrs","min","s","sec","ppm","ppb","bar","Î©","ohm","J","kJ","Wh","kWh",
    "æ ªå¼ä¼šç¤¾","æœ‰é™ä¼šç¤¾","åˆè³‡ä¼šç¤¾","åˆåä¼šç¤¾","åˆåŒä¼šç¤¾","Inc","Inc.","Ltd","Ltd.","Co","Co.","Corp","Corp.","LLC",
    "GmbH","AG","BV","B.V.","S.A.","S.p.A.","ï¼ˆæ ªï¼‰","ãˆ±","ï¼ˆæœ‰ï¼‰",
    "ä»¥ä¸Š", "ä»¥ä¸‹"
]

# çµ±åˆãƒªã‚¹ãƒˆã®ä½œæˆ
_stopwords_original_list = (
    _sw_general + 
    _sw_patent_terms + 
    _sw_structure + 
    _sw_it_control + 
    _sw_chemistry + 
    _sw_misc
)


def get_stopwords():
    """å…¨è§’åŠè§’ã‚’æ­£è¦åŒ–ã—ãŸã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚»ãƒƒãƒˆã‚’è¿”ã™"""
    def expand_to_full_width(words):
        expanded = set(words)
        hankaku = string.ascii_letters + string.digits
        zenkaku = "ï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™"
        trans = str.maketrans(hankaku, zenkaku)
        for w in words:
            if any(c in hankaku for c in w): expanded.add(w.translate(trans))
        return sorted(list(expanded))
    
    return set(expand_to_full_width(_stopwords_original_list))

# ==================================================================
# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š (å…±é€š) ---
# ==================================================================
def render_sidebar():
    """å…±é€šã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’æç”»ã™ã‚‹"""

    
    # å…±é€šCSSã®é©ç”¨
    st.markdown("""
    <style>
        html, body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; }
        
        /* H1 Title Spacing */
        [data-testid="stSidebar"] h1 { 
            color: #003366; 
            font-weight: 900 !important; 
            font-size: 2.5rem !important; 
            margin-top: 0 !important; 
            padding-top: 0 !important; 
            margin-bottom: 0 !important;
        }
        h1 { color: #003366; font-weight: 700; }
        h2, h3 { color: #333333; font-weight: 500; border-bottom: 2px solid #f0f0f0; padding-bottom: 5px; }
        
        /* Hide default nav */
        [data-testid="stSidebarNav"] { display: none !important; }
        
        /* Remove Top Whitespace (Robust Selectors) */
        section[data-testid="stSidebar"] > div:first-child { padding-top: 0rem; }
        [data-testid="stSidebarUserContent"] { padding-top: 0rem; }
        [data-testid="stSidebar"] .block-container { padding-top: 0rem; padding-bottom: 1rem; }
        
        .block-container { padding-top: 2rem; padding-bottom: 2rem; }
        .stButton>button { font-weight: 600; }
        .stTabs [data-baseweb="tab-list"] { gap: 8px; }
        .stTabs [data-baseweb="tab"] { background-color: #f0f2f6; border-radius: 8px 8px 0 0; padding: 10px 15px; }
        .stTabs [aria-selected="true"] { background-color: #ffffff; border-bottom: 2px solid #003366; }
        [data-testid="stSidebar"] h3 { border-bottom: none !important; padding-bottom: 10px !important; }
    </style>
    """, unsafe_allow_html=True)

    with st.sidebar:
        st.title("APOLLO") 
        st.markdown("Advanced Patent & Overall Landscape-analytics Logic Orbiter")
        st.markdown("**v5.2.0**")
        st.markdown("---")
        st.subheader("Home"); st.page_link("Home.py", label="Mission Control", icon="ğŸ›°ï¸")
        st.subheader("Modules")
        st.page_link("pages/1_ğŸŒ_ATLAS.py", label="ATLAS", icon="ğŸŒ")
        st.page_link("pages/2_ğŸ’¡_CORE.py", label="CORE", icon="ğŸ’¡")
        st.page_link("pages/3_ğŸš€_Saturn_V.py", label="Saturn V", icon="ğŸš€")
        st.page_link("pages/7_ğŸ¦…_EAGLE.py", label="EAGLE", icon="ğŸ¦…")
        st.page_link("pages/4_ğŸ“ˆ_MEGA.py", label="MEGA", icon="ğŸ“ˆ")
        st.page_link("pages/5_ğŸ§­_Explorer.py", label="Explorer", icon="ğŸ§­")
        st.page_link("pages/6_ğŸ”—_CREW.py", label="CREW", icon="ğŸ”—")
        st.page_link("pages/8_ğŸ“_VOYAGER.py", label="VOYAGER", icon="ğŸ“")
        st.markdown("---")
        st.caption("ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³:\n1. Mission Control ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€å‰å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n2. ä¸Šã®ãƒªã‚¹ãƒˆã‹ã‚‰åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’é¸æŠã—ã¾ã™ã€‚")
        st.markdown("---")
        st.caption("Â© 2025-2026 ã—ã°ã‚„ã¾")

# ==================================================================
# --- 4. ãƒ†ãƒ¼ãƒè¨­å®š (å…±é€š) ---
# ==================================================================
def get_theme_config(theme_name):
    """ãƒ†ãƒ¼ãƒã«å¿œã˜ãŸã‚«ãƒ©ãƒ¼è¨­å®šã‚’è¿”ã™"""
    import plotly.express as px
    
    themes = {
        "APOLLO Standard": {
            "bg_color": "#ffffff",
            "text_color": "#333333",
            "sidebar_bg": "#f8f9fa",
            "plotly_template": "plotly_white",
            "color_sequence": px.colors.qualitative.G10,
            "accent_color": "#003366",
            "density_scale": "Blues",
            "css": """
                html, body { background-color: #ffffff; color: #333333; }
                [data-testid="stSidebar"] { background-color: #f8f9fa; }
                [data-testid="stHeader"] { background-color: #ffffff; }
                h1, h2, h3 { color: #003366; }
            """
        },
        "Modern Presentation": {
            "bg_color": "#fdfdfd",
            "text_color": "#2c3e50",
            "sidebar_bg": "#eaeaea",
            "plotly_template": "plotly_white",
            "color_sequence": ["#264653", "#2a9d8f", "#e9c46a", "#f4a261", "#e76f51", "#8ab17d"],
            "accent_color": "#264653",
            "density_scale": "Teal",
            "css": """
                html, body { background-color: #fdfdfd; color: #2c3e50; font-family: "Helvetica Neue", Arial, sans-serif; }
                [data-testid="stSidebar"] { background-color: #eaeaea; }
                [data-testid="stHeader"] { background-color: #fdfdfd; }
                h1, h2, h3 { color: #264653; font-family: "Georgia", serif; }
                .stButton>button { background-color: #264653; color: white; border-radius: 0px; }
            """
        }
    }
    return themes.get(theme_name, themes["APOLLO Standard"])

# ==================================================================
# --- 5. Snapshot (VOYAGERé€£æº) ---
# ==================================================================
def calculate_hhi(counts):
    """ãƒ˜ãƒ«ãƒ•ã‚£ãƒ³ãƒ€ãƒ¼ãƒ«ãƒ»ãƒãƒ¼ã‚·ãƒ¥ãƒãƒ³æŒ‡æ•° (HHI) ã‚’è¨ˆç®—ã—ã€å…¬å–å§”åŸºæº–ã§åˆ¤å®šã™ã‚‹"""
    if not counts or sum(counts) == 0: return 0.0, "ãƒ‡ãƒ¼ã‚¿ä¸è¶³"
    
    total = sum(counts)
    shares = [c / total for c in counts]
    hhi = sum([s ** 2 for s in shares])
    
    # å…¬æ­£å–å¼•å§”å“¡ä¼šã®åŸºæº– (0-1ã‚¹ã‚±ãƒ¼ãƒ«)
    if hhi < 0.10: status = "ç«¶äº‰çš„ (åˆ†æ•£)"
    elif hhi < 0.18: status = "ä¸­ç¨‹åº¦ã®é›†ä¸­"
    else: status = "å¯¡å çš„ (é«˜é›†ä¸­)"
    
    return hhi, status

def calculate_cagr_slope(df_subset, year_col='year'):
    """å¹´å¹³å‡æˆé•·ç‡(CAGR)ã¨ãƒˆãƒ¬ãƒ³ãƒ‰(Slope)ã‚’è¨ˆç®—ã™ã‚‹"""
    if year_col not in df_subset.columns: return None, None
    
    years = df_subset[year_col].dropna().astype(int)
    if years.empty: return None, None
    
    counts = years.value_counts().sort_index()
    if len(counts) < 2: return 0.0, "Stable"
    
    # ç›´è¿‘3-5å¹´ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¦‹ã‚‹
    y_vals = counts.index.values
    c_vals = counts.values
    
    # Slope (ç·šå½¢å›å¸°)
    try:
        slope, _ = np.polyfit(y_vals, c_vals, 1)
        if slope > 0.5: trend = "æ€¥ä¸Šæ˜‡ ğŸ“ˆ"
        elif slope > 0: trend = "å¢—åŠ å‚¾å‘ â†—ï¸"
        elif slope > -0.5: trend = "æ¸›å°‘å‚¾å‘ â†˜ï¸"
        else: trend = "å¤±é€Ÿ ğŸ“‰"
    except:
        trend = "ä¸æ˜"
        slope = 0
        
    # CAGR (æœ€åˆã¨æœ€å¾Œ)
    try:
        start_val = c_vals[0] if c_vals[0] > 0 else 1
        end_val = c_vals[-1]
        n_years = max(1, y_vals[-1] - y_vals[0])
        cagr = (end_val / start_val) ** (1/n_years) - 1
    except:
        cagr = 0.0
        
    return cagr, trend

@st.cache_data(show_spinner=False)
def generate_rich_summary(df_target, title_col='title', abstract_col='abstract', n_representatives=5):
    """
    VOYAGER v5.1ç”¨ã®é«˜è§£åƒåº¦ã‚µãƒãƒªã‚’ç”Ÿæˆã™ã‚‹ (Cached)
    - çµ±è¨ˆæƒ…å ± (HHI, CAGR, Trend)
    - ä»£è¡¨ç‰¹è¨± (Centroid Distance)
    """
    summary = {
        "stats": {},
        "representatives": []
    }
    
    # 1. çµ±è¨ˆæƒ…å ±ã®è¨ˆç®— (å¹´æ¬¡æ¨ç§»ãŒã‚ã‚‹å ´åˆ)
    if 'year' in df_target.columns:
        cagr, trend = calculate_cagr_slope(df_target)
        summary['stats']['cagr'] = f"{cagr:.1%}" if cagr is not None else "N/A"
        summary['stats']['trend'] = trend if trend else "N/A"

    # 2. HHI (å¸‚å ´é›†ä¸­åº¦) ã®è¨ˆç®—
    try:
        # å‡ºé¡˜äººæƒ…å ± ('applicant_main') ã‚’åˆ©ç”¨ã—ã¦å¸‚å ´é›†ä¸­åº¦ã‚’ç®—å‡º
        if 'applicant_main' in df_target.columns:
            all_apps = [a for sublist in df_target['applicant_main'] for a in sublist]
            counts = pd.Series(all_apps).value_counts().tolist()
            hhi, hhi_status = calculate_hhi(counts)
            summary['stats']['hhi'] = hhi
            summary['stats']['hhi_status'] = hhi_status
    except: pass
        
    # 3. ä»£è¡¨ç‰¹è¨±ã®æŠ½å‡º (Centroid Distance)
    if 'sbert_embeddings' in st.session_state and not df_target.empty:
        try:
            # df_targetã®indexã‚’ä½¿ã£ã¦embeddingsã‚’æŠ½å‡º
            # å‰æ: df_mainã®indexãŒresetã•ã‚Œã¦ãŠã‚‰ãšã€embeddingsã¨1å¯¾1å¯¾å¿œã—ã¦ã„ã‚‹ã“ã¨
            valid_indices = [i for i in df_target.index if i < len(st.session_state.sbert_embeddings)]
            
            if valid_indices:
                vectors = st.session_state.sbert_embeddings[valid_indices]
                centroid = np.mean(vectors, axis=0)
                
                # é‡å¿ƒã¨ã®è·é›¢è¨ˆç®— (Cosine Similarityç›¸å½“)
                dots = np.dot(vectors, centroid)
                
                # ä¸Šä½Nä»¶ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
                top_n_local_indices = np.argsort(dots)[::-1][:n_representatives]
                top_global_indices = [valid_indices[i] for i in top_n_local_indices]
                
                # ãƒ‡ãƒ¼ã‚¿å–å¾—
                reps = []
                invalid_count = 0
                
                # Column mapping for enhanced info
                col_map = st.session_state.get('col_map', {})
                app_col = col_map.get('applicant', 'applicant')
                
                for idx in top_global_indices:
                    try:
                        row = st.session_state.df_main.loc[idx]
                        t_val = str(row.get(title_col, ''))
                        a_val = str(row.get(abstract_col, ''))
                        
                        # Enhanced Info
                        y_val = str(row.get('year', 'N/A'))
                        app_val = "N/A"
                        if app_col and app_col in row:
                            val = row[app_col]
                            if isinstance(val, list):
                                # Clean join: Filter out None/nan/invalid
                                clean_vals = [str(x).strip() for x in val if x and str(x).lower() != 'nan']
                                app_val = ", ".join(clean_vals)
                            else: app_val = str(val)
                        
                        # Check validity
                        if (not t_val or t_val == 'nan') and (not a_val or a_val == 'nan'):
                             invalid_count += 1
                             title = "No Title"
                             abstract = "No Abstract"
                        else:
                             title = t_val if t_val and t_val != 'nan' else "No Title"
                             abstract = a_val if a_val and a_val != 'nan' else "No Abstract"
                        
                        title = title.replace('\n', ' ')
                        abstract = abstract.replace('\n', ' ')[:200] + "..." 
                        
                        # Clean up Applicant (truncate if too long)
                        if len(app_val) > 30: app_val = app_val[:30] + "..."
                        
                        reps.append(f"- ã€{title}ã€‘ (å‡ºé¡˜: {y_val}, {app_val}) {abstract}")
                    except: pass
                
                # If mostly invalid, don't show
                if len(reps) > 0 and (invalid_count / len(reps)) > 0.5:
                     summary['representatives'] = [] # Suppress
                else:
                     summary['representatives'] = reps

        except Exception as e:
            summary['error'] = str(e)

    return summary

def render_snapshot_button(title, description, key, fig=None, data_summary=None):
    """
    ã‚°ãƒ©ãƒ•ã‚„ãƒ‡ãƒ¼ã‚¿ã‚’VOYAGERç”¨ã«ä¿å­˜ã™ã‚‹ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹
    """
    if 'snapshots' not in st.session_state:
        st.session_state['snapshots'] = []

    # Check if already saved
    is_saved = any(s['id'] == key for s in st.session_state['snapshots'])
    
    btn_label = "ğŸ“¸ Snapshot Saved" if is_saved else "ğŸ“¸ Save Snapshot"
    btn_type = "primary" if not is_saved else "secondary"
    
    if st.button(btn_label, key=f"snap_btn_{key}", type=btn_type, disabled=is_saved):
        # Determine Module Name (Prioritize data_summary['module'] if available)
        module_name = st.session_state.get('current_page', 'Unknown')
        if data_summary and isinstance(data_summary, dict) and 'module' in data_summary:
            module_name = data_summary['module']

        snapshot_data = {
            'id': key,
            'title': title,
            'description': description,
            'data_summary': data_summary,
            'module': module_name,
            'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # Image conversion (Best effort)
        import io
        img_bytes = None
        
        try:
            if fig:
                # Plotly
                if hasattr(fig, 'to_image'):
                    try:
                        # --- Smart Resolution & Aspect Ratio ---
                        # Base Width for High-Res
                        base_width = 1600
                        use_width = base_width
                        use_height = 1000 # Default fallback
                        
                        # 1. Map Mode (Saturn V): Match Data Aspect Ratio (1:1)
                        # 2. Chart Mode (ATLAS): Enforce Wide Format (16:9)
                        
                        is_saturn_v = module_name == 'Saturn V'
                        
                        try:
                            if is_saturn_v:
                                # SATURN V: Calculate aspect ratio from axis ranges
                                xaxis = fig.layout.xaxis
                                yaxis = fig.layout.yaxis
                                if xaxis.range and yaxis.range:
                                    x_range = xaxis.range[1] - xaxis.range[0]
                                    y_range = yaxis.range[1] - yaxis.range[0]
                                    if x_range > 0 and y_range > 0:
                                        # Calculate height to match data aspect ratio
                                        ratio = x_range / y_range
                                        calc_height = base_width / ratio
                                        # Clamp height slightly less aggressively for maps
                                        calc_height = max(600, min(calc_height, 2400))
                                        use_height = int(calc_height)
                                    else:
                                        use_height = int(base_width * 0.618)
                                else:
                                    # Fallback if no ranges
                                    use_height = 1000
                            else:
                                # ATLAS / Charts: Standard Wide Format (16:9)
                                use_height = int(base_width * 9 / 16)
                                
                        except:
                            use_height = 1000

                        # Increase scale to 3.0 for Ultra High Res
                        img_bytes = fig.to_image(format="png", width=use_width, height=use_height, scale=3.0)
                    except Exception as e:
                        snapshot_data['image_error'] = f"Plotly Image Error (Kaleido): {str(e)}"
                        st.warning(f"ç”»åƒåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ (Kaleido Check): {e}")
                
                # Matplotlib
                elif hasattr(fig, 'savefig'):
                    try:
                        buf = io.BytesIO()
                        fig.savefig(buf, format='png', bbox_inches='tight')
                        buf.seek(0)
                        img_bytes = buf.getvalue()
                    except Exception as e:
                        snapshot_data['image_error'] = f"Matplotlib Image Error: {str(e)}"
                        st.warning(f"ç”»åƒåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                        
        except Exception as e:
            snapshot_data['image_error'] = f"General Image Error: {str(e)}"
            
        snapshot_data['image'] = img_bytes
        st.session_state['snapshots'].append(snapshot_data)
        st.rerun()

    if is_saved:
        st.success(f"'{title}' ã‚’VOYAGERãƒã‚±ãƒƒãƒˆã«ä¿å­˜ã—ã¾ã—ãŸ")

# ==================================================================
# --- 5. AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ (å…±é€š) ---
# ==================================================================
def generate_ai_cluster_prompt(df_source, cluster_col, target_cols, tfidf_matrix, feature_names, n_samples=5):
    """ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ä»£è¡¨æ–‡çŒ®ã‚’æŠ½å‡ºã—ã€å‘½åç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    if df_source.empty: return "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
    
    unique_clusters = sorted([c for c in df_source[cluster_col].unique() if c != -1])
    if not unique_clusters: return "æœ‰åŠ¹ãªã‚¯ãƒ©ã‚¹ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

    # embeddingã‚«ãƒ©ãƒ ã®ç‰¹å®š
    if 'umap_x' in df_source.columns and 'umap_y' in df_source.columns:
        embedding_cols = ['umap_x', 'umap_y']
    elif 'drill_x' in df_source.columns and 'drill_y' in df_source.columns:
        embedding_cols = ['drill_x', 'drill_y']
    elif 'x' in df_source.columns and 'y' in df_source.columns: # MEGAå¯¾å¿œ
        embedding_cols = ['x', 'y']
    else:
        return "åŸ‹ã‚è¾¼ã¿åº§æ¨™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"

    sampled_docs = []
    
    for cid in unique_clusters:
        c_df = df_source[df_source[cluster_col] == cid]
        if c_df.empty: continue
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º (TF-IDF)
        keywords_str = ""
        try:
            valid_indices = [i for i in c_df.index if i < tfidf_matrix.shape[0]]
            if valid_indices:
                sub_matrix = tfidf_matrix[valid_indices]
                mean_vec = np.array(sub_matrix.mean(axis=0)).flatten()
                top_idx = np.argsort(mean_vec)[::-1][:10] # Top 10 words
                keywords = [feature_names[i] for i in top_idx]
                keywords_str = ", ".join(keywords)
        except Exception as e:
            keywords_str = f"(æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e})"

        # é‡å¿ƒè¨ˆç®—
        coords = c_df[embedding_cols].values
        centroid = coords.mean(axis=0)
        
        # é‡å¿ƒã«è¿‘ã„é †ã«ã‚½ãƒ¼ãƒˆ
        dists = euclidean_distances(coords, centroid.reshape(1, -1)).flatten()
        top_indices = np.argsort(dists)[:n_samples]
        
        docs = []
        for idx in top_indices:
            row = c_df.iloc[idx]
            text_parts = []
            for col in target_cols:
                if col and col in row and pd.notna(row[col]):
                    val = str(row[col]).replace('\n', ' ')
                    text_parts.append(val)
            docs.append(f"  - {' '.join(text_parts)}")
        
        sampled_docs.append(f"Cluster {cid}:\n[ç‰¹å¾´èª] {keywords_str}\n[ä»£è¡¨ç‰¹è¨±]\n" + "\n".join(docs))

    sampled_docs_str = "\n\n".join(sampled_docs)

    prompt = f"""
ã‚ãªãŸã¯ç†Ÿç·´ã—ãŸç‰¹è¨±æƒ…å ±ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ã€Œã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç‰¹å¾´èªã¨ä»£è¡¨çš„ç‰¹è¨±ãƒªã‚¹ãƒˆã€ã‚’åˆ†æã—ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã®å†…å®¹ã‚’ç«¯çš„ã«è¡¨ã™**ã€ŒçŸ­ã„èª¬æ˜ãƒ©ãƒ™ãƒ«ï¼ˆæ—¥æœ¬èªï¼‰ã€**ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

# åˆ¶ç´„äº‹é …
- ãƒ©ãƒ™ãƒ«ã¯**20æ–‡å­—ä»¥å†…**ã®æ—¥æœ¬èªã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
- å°‚é–€ç”¨èªã‚’é©åˆ‡ã«ä½¿ç”¨ã—ã€æŠ€è¡“çš„ç‰¹å¾´ã‚„è§£æ±ºèª²é¡Œã‚’åæ˜ ã•ã›ã¦ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯ **JSONå½¢å¼ã®ã¿** ã¨ã—ã¦ãã ã•ã„ã€‚è§£èª¬ã¯ä¸è¦ã§ã™ã€‚

# å‡ºåŠ›ä¾‹
{{
  "0": "å…¨å›ºä½“é›»æ± ã®å›ºä½“é›»è§£è³ª",
  "1": "ç”»åƒèªè­˜ã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥",
  "2": "ã‚«ãƒ¼ãƒœãƒ³ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ç‡ƒæ–™è£½é€ "
}}

# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (JSON)
{{
  "ã‚¯ãƒ©ã‚¹ã‚¿ID (æ•´æ•°)": "ææ¡ˆãƒ©ãƒ™ãƒ«",
  ...
}}

# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿
{sampled_docs_str}
"""
    return prompt

def render_ai_label_assistant(df_source, cluster_col, label_map_key, col_map, tfidf_matrix, feature_names, widget_key_prefix=None):
    """AIãƒ©ãƒ™ãƒ«ã‚µã‚¸ã‚§ã‚¹ãƒˆUI (å…±é€šéƒ¨å“)"""
    with st.expander("AIã«ã‚ˆã‚‹ãƒ©ãƒ™ãƒ«ã‚µã‚¸ã‚§ã‚¹ãƒˆ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)"):
        st.markdown("LLM (ChatGPTç­‰) ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŠ•ã’ã€çµæœã®JSONã‚’å–ã‚Šè¾¼ã‚€ã“ã¨ã§ãƒ©ãƒ™ãƒ«ã‚’è‡ªå‹•è¨­å®šã—ã¾ã™ã€‚")
        
        col_s1, col_s2 = st.columns([1, 2])
        with col_s1:
            n_samples_ai = st.number_input("1ã‚¯ãƒ©ã‚¹ã‚¿ã‚ãŸã‚Šã®ã‚µãƒ³ãƒ—ãƒ«æ•°", min_value=1, value=5, key=f"ai_n_samples_{label_map_key}")
        
        if st.button("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ", key=f"ai_gen_btn_{label_map_key}"):
            target_cols = [col_map.get('title'), col_map.get('abstract')]
            prompt = generate_ai_cluster_prompt(df_source, cluster_col, target_cols, tfidf_matrix, feature_names, n_samples=n_samples_ai)
            st.session_state[f"ai_prompt_{label_map_key}"] = prompt
        
        if f"ai_prompt_{label_map_key}" in st.session_state:
            st.code(st.session_state[f"ai_prompt_{label_map_key}"], language="markdown")
            st.info("ğŸ‘† å³ä¸Šã®ã‚³ãƒ”ãƒ¼ãƒœã‚¿ãƒ³ã§ã‚³ãƒ”ãƒ¼ã—ã€LLMã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

        st.markdown("---")
        st.markdown("**çµæœã®å–ã‚Šè¾¼ã¿ (JSON)**")
        json_input = st.text_area("LLMã®å‡ºåŠ›JSONã‚’è²¼ã‚Šä»˜ã‘:", height=150, key=f"ai_json_input_{label_map_key}")
        
        if st.button("ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚’é©ç”¨", key=f"ai_apply_btn_{label_map_key}"):
            try:
                # JSONã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° (Markdownã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯é™¤å»)
                cleaned_json = re.sub(r'^```json\s*|\s*```$', '', json_input.strip(), flags=re.MULTILINE)
                data = json.loads(cleaned_json)
                
                # keyå¤‰æ› (str -> int) & é©ç”¨
                current_map = st.session_state[label_map_key]
                count = 0
                for cid_str, label in data.items():
                    try:
                        cid = int(cid_str)
                        # df_sourceã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚«ãƒ©ãƒ ã«å­˜åœ¨ã™ã‚‹IDã‹ç¢ºèª
                        unique_cids = df_source[cluster_col].unique()
                        
                        if cid in current_map or cid in unique_cids: # å­˜åœ¨ã™ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ã®ã¿
                            new_val = f"[{cid}] {label}"
                            current_map[cid] = new_val
                            
                            # ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®ã‚¹ãƒ†ãƒ¼ãƒˆã‚‚å¼·åˆ¶æ›´æ–°ã—ã¦ã€UIä¸Šã®è¡¨ç¤ºã‚’åŒæœŸã•ã›ã‚‹
                            if widget_key_prefix:
                                w_key = f"{widget_key_prefix}_{cid}"
                                if w_key in st.session_state:
                                    st.session_state[w_key] = new_val
                            count += 1
                    except: pass
                
                # åæ˜  (session_stateã®ãƒãƒƒãƒ—ã¯å‚ç…§æ¸¡ã—ã•ã‚Œã¦ã„ã‚‹å‰æã ãŒã€å¿µã®ãŸã‚å†ä»£å…¥)
                st.session_state[label_map_key] = current_map
                
                # [Saturn V] ãƒ©ãƒ™ãƒ«ã‚«ãƒ©ãƒ ã®æ›´æ–°
                if label_map_key == "saturnv_labels_map" and 'df_main' in st.session_state:
                   # ãƒ©ãƒ™ãƒ«æ›´æ–°ã‚’åæ˜ 
                   st.session_state.df_main['cluster_label'] = st.session_state.df_main['cluster'].map(current_map)
                elif label_map_key == "drill_labels_map" and 'df_drilldown_result' in st.session_state:
                   st.session_state.df_drilldown_result['drill_cluster_label'] = st.session_state.df_drilldown_result['drill_cluster'].map(current_map)

                # [MEGA] ãƒ©ãƒ™ãƒ«ã‚«ãƒ©ãƒ ã®æ›´æ–°
                elif label_map_key == "mega_drill_labels_map" and 'df_drilldown' in st.session_state:
                   st.session_state.df_drilldown['label'] = st.session_state.df_drilldown['cluster_id'].map(current_map)
                   st.session_state.sbert_sub_cluster_map_auto = current_map

                st.success(f"{count} ä»¶ã®ãƒ©ãƒ™ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")
                st.rerun()
                
            except Exception as e:
                st.error(f"JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")

def create_label_editor_ui(original_map, current_map, key_prefix):
    """æ‰‹å‹•ãƒ©ãƒ™ãƒ«ç·¨é›†UIæ©Ÿèƒ½ (å…±é€š)"""
    widgets_dict = {}
    sorted_ids = sorted([cid for cid in original_map.keys() if cid != -1])
    for cluster_id in sorted_ids:
        orig_label = original_map.get(cluster_id, "")
        curr_label = current_map.get(cluster_id, orig_label)
        if orig_label == "(è©²å½“ãªã—)": continue
        col1, col2 = st.columns([2, 3])
        with col1: st.markdown(f":green[{orig_label}]")
        with col2:
            key = f"{key_prefix}_{cluster_id}"
            if key not in st.session_state:
                st.session_state[key] = curr_label
            # valueå¼•æ•°ã‚’æŒ‡å®šã›ãšã€keyçµŒç”±ã§session_stateã®å€¤ã‚’ä½¿ç”¨ã•ã›ã‚‹
            new_label = st.text_input(f"Edit {cluster_id}", label_visibility="collapsed", key=key)
            widgets_dict[cluster_id] = new_label
    if -1 in original_map:
        orig_noise = original_map[-1]
        curr_noise = current_map.get(-1, orig_noise)
        col1, col2 = st.columns([2, 3])
        with col1: st.markdown(f":green[{orig_noise}]")
        with col2:
            st.text_input(f"noise_label", value=curr_noise, disabled=True, key=f"{key_prefix}_noise")
            widgets_dict[-1] = curr_noise
    return widgets_dict

def update_fig_layout(fig, title, height=1000, width=800, theme_config=None, show_axes=False, show_legend=True):
    """Plotlyã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’çµ±ä¸€çš„ã«æ›´æ–°ã™ã‚‹"""
    if theme_config is None:
        return fig
    
    # Sanitize title to remove implicit/explicit HTML tags (e.g. <b>)
    if isinstance(title, str):
        title = re.sub(r'<[^>]+>', '', title)

    layout_params = dict(
        template=theme_config["plotly_template"],
        title=dict(text=title, font=dict(size=18, color=theme_config["text_color"], family="Helvetica Neue", weight="normal")),
        paper_bgcolor=theme_config["bg_color"],
        plot_bgcolor=theme_config["bg_color"],
        font=dict(color=theme_config["text_color"], family="Helvetica Neue"),
        height=height,
        width=width,
        margin=dict(l=20, r=20, t=60, b=20),
        legend=dict(
            orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1,
            bgcolor="rgba(255,255,255,0.8)", bordercolor="#eee", borderwidth=1
        )
    )

    if not show_legend:
        layout_params['showlegend'] = False

    if not show_axes:
        layout_params['xaxis'] = dict(visible=False, showgrid=False, zeroline=False, showticklabels=False)
        layout_params['yaxis'] = dict(
            visible=False, showgrid=False, zeroline=False, showticklabels=False,
            scaleanchor="x", scaleratio=1
        )
    else:
        if "width" in layout_params:
            del layout_params["width"]

        layout_params['xaxis'] = dict(
            visible=True, showgrid=False, zeroline=False, showline=False, showticklabels=True
        )
        layout_params['yaxis'] = dict(
            visible=True, showgrid=True, gridcolor='#eee', zeroline=False, showline=False, showticklabels=True
        )

    fig.update_layout(**layout_params)
    return fig
